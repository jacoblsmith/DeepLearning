{
 "metadata": {
  "name": "Abilene"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Initial Investigation of Abilene Data Set and Deep Learning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.io as sio\n",
      "import pickle\n",
      "\n",
      "eps = 2.2e-16"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat ../data/abilene/README.TM-ESTIMATION"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The file TM-ESTIMATION.zip contains this README file and the file\r\n",
        "SAND_TM_Estimation_Data.mat, a Matlab .mat data file.  This data file\r\n",
        "can be read, from within Matlab, simply by entering \r\n",
        "\r\n",
        "   load SAND_TM_Estimation_Data.mat\r\n",
        "\r\n",
        "The data file contains data relevant to the case study in Section 9.3.3\r\n",
        "of SAND.  The data are based on measurements of origin-destination flows on\r\n",
        "the Abilene network, taken continuously over a seven-day period, starting \r\n",
        "December 22, 2003.  In particular, these data represent aggregate flow volumes\r\n",
        "for 12x24x7 = 2016 consecutive 5 minute time intervals over the week,\r\n",
        "across 11x11 = 121 origin-destination pairs (including self-loops)\r\n",
        "in the 11 node network (where nodes represent points-of-presence (PoPs)).\r\n",
        "\r\n",
        "The following variables are found in the .mat file\r\n",
        "\r\n",
        "X          a 2016x121 matrix of flow volumes\r\n",
        "A          a 30x121 matrix, describing the routing of the 121 flows over the 30\r\n",
        "           edges between adjacent nodes in the Abilene network\r\n",
        "odnames    a 121x1 character vector of origin-destination pair names\r\n",
        "edgenames  a 30x1 character vector of node pairs sharing an edge\r\n",
        "\r\n",
        "The ordering of pairs of names in `odnames' and `edgenames' corresponds to \r\n",
        "the orderings in X and A.  Approximate link counts can be synthesized by\r\n",
        "defining Y = A*X' .\r\n",
        "\r\n",
        "For additional details on the original flow data, please see\r\n",
        "\r\n",
        "\tA. Lakhina, K. Papgiannaki, C. Crovella, M. Diot, E. Kolaczyk,\r\n",
        "\tand N. Taft, \"Structural analysis of network traffic flows\",\r\n",
        "\tin Proceedings of the ACM Sigmetrics Conference, 2004.\r\n",
        "\r\n",
        "In using this data, please cite the above article as the source.\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abdat = sio.loadmat('../data/abilene/SAND_TM_Estimation_Data.mat')\n",
      "X = abdat['X']\n",
      "A = abdat['A']\n",
      "odnames = abdat['odnames']\n",
      "odnames = np.asarray([str(v[0][0]).strip() for v in odnames] )\n",
      "edgenames = abdat['edgenames']\n",
      "edgenames = np.asarray([str(v[0][0]).strip() for v in edgenames] )\n",
      "\n",
      "abdat['odnames'] = odnames\n",
      "abdat['edgenames'] = edgenames\n",
      "\n",
      "pickle.dump(abdat, open('../data/abilene/abilene_data.pickle','wb'))\n",
      "\n",
      "x = (X / np.tile(np.reshape(np.sqrt(np.sum(np.multiply(X,X),1) + eps),(X.shape[0],1)),X.shape[1]))\n",
      "y = x.sum(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#v = edgenames[0]\n",
      "edges = [tuple(v.split('-')) for v in edgenames]\n",
      "orig_dest = [tuple(v.split('-')) for v in odnames]\n",
      "\n",
      "all_names = []\n",
      "for e in edges:\n",
      "    all_names += list(e)\n",
      "all_names = sorted(set(all_names))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "T = X.shape[0]\n",
      "idx = pd.date_range('2003-12-23', periods=T, freq='5min')\n",
      "Xpd = pd.DataFrame(X,index=idx,columns=odnames)\n",
      "xpd = pd.DataFrame(x,index=idx,columns=odnames)\n",
      "\n",
      "if False:\n",
      "    # origin with all destinations\n",
      "    for n in all_names:\n",
      "        origin = xpd.select(lambda x: x.split('-')[0] == n,axis=1)\n",
      "        C = origin.shape[1]\n",
      "        fig = plt.figure(figsize(18,10))\n",
      "        origin.plot()\n",
      "        plt.title(n)\n",
      "\n",
      "# origin graphs with destination summed\n",
      "if False:\n",
      "    for n in all_names:\n",
      "        origin = xpd.select(lambda x: x.split('-')[0] == n,axis=1)\n",
      "        dest = xpd.select(lambda x: x.split('-')[1] == n,axis=1)\n",
      "        C = origin.shape[1]\n",
      "        fig = plt.figure(figsize(18,3))\n",
      "        origin.sum(axis=1).plot()\n",
      "        dest.sum(axis=1).plot()\n",
      "        plt.legend(['Origin', 'Destination'])\n",
      "        plt.title('%s'%n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}